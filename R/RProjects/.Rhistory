str(Gaged)
str(Modeled
)
monthobs<-subset(Gaged,month_val==month)
monthmod<-subset(Modeled,month_val==month)
GagedTmp <- aggregate(monthobs$discharge, list(monthobs$year_val), FUN = mean, na.rm=TRUE)
ModeledTmp <- aggregate(monthmod$discharge, list(monthmod$year_val), FUN = mean, na.rm=TRUE)
i <- 2+m
NSEv[i] <- nse(GagedTmp[,c],ModeledTmp[,c])
NSELOGv[i] <- nselog(GagedTmp[,c],ModeledTmp[,c])
RMSEv[i] <- rmse(GagedTmp[,c],ModeledTmp[,c])
PBIASv[i] <- pbias(GagedTmp[,c],ModeledTmp[,c])
PEARSONv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="pearson")
SPEARMANv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="spearman")
}
m
str_pad(m,2,side="left",pad="0")
library(stringr)
str_pad
?str_c
?str_dup
?str_c
?paste
m
ifelse(nchar(m)<2,paste("0",m,sep=""),m)
library(devtools)
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/")
load_all("NWCCompare/",reset = TRUE)
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/NWCCompare")
document()
check()
run_examples()
# test()   Assumes testthat type tests in GLRI/inst/tests
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/")
build("NWCCompare")
install("NWCCompare")
source('C:/Users/jlthomps/Desktop/git/USGS-NWC/R/standalone_scripts/stats_compare_new.r', echo=TRUE)
model_url="http://cida.usgs.gov/nwc/thredds/sos/watersmart/afinch/afinch-SE-SPARSE1-0.1.nc?request=GetObservation&service=SOS&version=1.0.0&offering"
#model_url="http://cida.usgs.gov/gdp/proxy/http://cida-wiwsc-gdp1qa.er.usgs.gov:8080/thredds/sos/watersmart/waters/waters-Special-0.3.nc?request=GetObservation&service=SOS&version=1.0.0&offering"
sos_url_temp="http://waterservices.usgs.gov/nwis/dv/?format=rdb,1.0&sites="
offering_temp='00003'
property_temp='00060'
drainage_url="http://waterservices.usgs.gov/nwis/site/?siteOutput=Expanded&site="
scenario_url=paste(substr(model_url,1,regexpr("Get",model_url)-1),"GetCapabilities&service=SOS&version=1.0.0",sep="")
setwd('/Users/jlthomps/Documents/R/')
system("rm graph*png")
system("rm monthly*txt")
#a<-read.csv(header=F,colClasses=c("character"),text=sites)
#a2<-read.csv(header=F,colClasses=c("character"),text=modsites)
#a<-read.csv("sites_waters_stat.txt",header=F,colClasses=c("character"))
#a2<-read.csv("sites_waters_stat.txt",header=F,colClasses=c("character"))
getcap<-getScenarioSites(scenario_url)
modprop<-getcap$modprop
a<-t(getcap$scenario_sites)
a2<-a
al<-length(a)
comment<-vector(length=al)
ObsFlowStats <- matrix(nrow=al,ncol=138)
ModFlowStats <- matrix(nrow=nrow(ObsFlowStats),ncol=ncol(ObsFlowStats))
GoFMetrics <- matrix(nrow=nrow(ObsFlowStats),ncol=108)
MonAnnGoF <- matrix(nrow=nrow(ObsFlowStats),ncol=84)
yv<-vector(length=al)
ymaxv<-vector(length=al)
i<-1
modsites<-a2[i]
url<-paste(model_url,'=',modsites,'&observedProperty=',modprop,sep='',collapse=NULL)
x_mod<-SWE_CSV_IHA(url)
if (length(sapply(x_mod,nchar))>1) {
startdate<-min(x_mod$date)
enddate<-max(x_mod$date)
interval<-''
}
startdate<-min(x_mod$date)
enddate<-max(x_mod$date)
interval<-''
latest<-''
sites=a[i]
url2<-paste(sos_url_temp,sites,'&startDT=',startdate,'&endDT=',enddate,'&statCd=',offering_temp,'&parameterCd=',property_temp,'&access=3',sep='')
x_obs <- retrieveNWISData(url2)
obs_data <- get_obsdata(x_obs)
x_mod$date <- as.Date(x_mod$date,format="%Y-%m-%d")
x_mod<-x_mod[x_mod$date>=min(x_obs$date) & x_mod$date<=max(x_obs$date), ]
drain_url<-paste(drainage_url,sites,sep="")
drain_area<-getDrainageArea(drain_url)
mod_data <- get_obsdata(x_mod)
countbyyr<-aggregate(obs_data$discharge, list(obs_data$wy_val), length)
countbyyr_mod<-aggregate(mod_data$discharge, list(mod_data$wy_val), length)
colnames(countbyyr)<-c('wy','num_samples')
colnames(countbyyr_mod)<-c('wy','num_samples')
sub_countbyyr<-subset(countbyyr,num_samples >= 365)
sub_countbyyr_mod<-subset(countbyyr_mod,num_samples >= 365)
include_yrs<-merge(sub_countbyyr,sub_countbyyr_mod)
obs_data<-merge(obs_data,include_yrs,by.x="wy_val",by.y="wy")
mod_data<-merge(mod_data,include_yrs,by.x="wy_val",by.y="wy")
yv[i]<-as.character(min(obs_data$date))
ymaxv[i]<-as.character(max(obs_data$date))
x_modz<-mod_data$discharge
x_obsz<-obs_data$discharge
dates<-as.Date(obs_data$date)
file<-paste("graph",toString(sites),".png",sep="")
#png(file)
ggof(x_modz,x_obsz,na.rm=FALSE,dates,main=modsites)
dev.copy(png,file)
dev.off()
file<-paste("monthly_mean_ts_obs",toString(sites),".txt",sep="")
monthly_mean<-monthly.mean.ts(obs_data)
write.table(monthly_mean,file=file,col.names=TRUE, row.names=FALSE, quote=FALSE, sep="\t")
file<-paste("monthly_mean_ts_mod",toString(sites),".txt",sep="")
monthly_mean<-monthly.mean.ts(mod_data)
write.table(monthly_mean,file=file,col.names=TRUE, row.names=FALSE, quote=FALSE, sep="\t")
obs_data <- obs_data[,c('wy_val','date','discharge','month_val','year_val','day_val','jul_val')]
mod_data <- mod_data[,c('wy_val','date','discharge','month_val','year_val','day_val','jul_val')]
ObsFlowStats[i,] <- FlowStats(obs_data,drain_area)
ModFlowStats[i,] <- FlowStats(mod_data,drain_area)
comment <- ""
GoFMetrics[i,] <- SiteGoF(obs_data,mod_data)
MonAnnGoF[i,] <- MonthlyAnnualGoF(obs_data,mod_data)
Gaged<-obs_data
Modeled<-mod_data
NSEv <- vector(length=14)
NSELOGv <- vector(length=length(NSEv))
RMSEv <- vector(length=length(NSEv))
PBIASv <- vector(length=length(NSEv))
PEARSONv <- vector(length=length(NSEv))
SPEARMANv <- vector(length=length(NSEv))
i <- 1
c <- 2
GagedTmp <- aggregate(Gaged$discharge, list(Gaged$year_val), FUN = mean, na.rm=TRUE)
ModeledTmp <- aggregate(Modeled$discharge, list(Modeled$year_val), FUN = mean, na.rm=TRUE)
NSEv[i] <- nse(GagedTmp[,c],ModeledTmp[,c])
NSELOGv[i] <- nselog(GagedTmp[,c],ModeledTmp[,c])
RMSEv[i] <- rmse(GagedTmp[,c],ModeledTmp[,c])
PBIASv[i] <- pbias(GagedTmp[,c],ModeledTmp[,c])
PEARSONv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="pearson")
SPEARMANv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="spearman")
i <- 2
c <- 3
GagedTmp <- aggregate(Gaged$discharge, list(Gaged$year_val,Gaged$month_val), FUN = mean, na.rm=TRUE)
ModeledTmp <- aggregate(Modeled$discharge, list(Modeled$year_val,Modeled$month_val), FUN = mean, na.rm=TRUE)
NSEv[i] <- nse(GagedTmp[,c],ModeledTmp[,c])
NSELOGv[i] <- nselog(GagedTmp[,c],ModeledTmp[,c])
RMSEv[i] <- rmse(GagedTmp[,c],ModeledTmp[,c])
PBIASv[i] <- pbias(GagedTmp[,c],ModeledTmp[,c])
PEARSONv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="pearson")
SPEARMANv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="spearman")
c <- 2
m<-1
month<-paste("0",m,sep="")
monthobs<-subset(Gaged,ifelse(nchar(month_val)<2,paste("0",month_val,sep=""),month_val)==month)
monthmod<-subset(Modeled,ifelse(nchar(month_val)<2,paste("0",month_val,sep=""),month_val)==month)
monthobs
monthmod
GagedTmp <- aggregate(monthobs$discharge, list(monthobs$year_val), FUN = mean, na.rm=TRUE)
ModeledTmp <- aggregate(monthmod$discharge, list(monthmod$year_val), FUN = mean, na.rm=TRUE)
i <- 2+m
NSEv[i] <- nse(GagedTmp[,c],ModeledTmp[,c])
NSELOGv[i] <- nselog(GagedTmp[,c],ModeledTmp[,c])
RMSEv[i] <- rmse(GagedTmp[,c],ModeledTmp[,c])
PBIASv[i] <- pbias(GagedTmp[,c],ModeledTmp[,c])
PEARSONv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="pearson")
SPEARMANv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="spearman")
m<-10
month<-paste("",m,sep="")
monthobs<-subset(Gaged,ifelse(nchar(month_val)<2,paste("0",month_val,sep=""),month_val)==month)
monthmod<-subset(Modeled,ifelse(nchar(month_val)<2,paste("0",month_val,sep=""),month_val)==month)
GagedTmp <- aggregate(monthobs$discharge, list(monthobs$year_val), FUN = mean, na.rm=TRUE)
ModeledTmp <- aggregate(monthmod$discharge, list(monthmod$year_val), FUN = mean, na.rm=TRUE)
i <- 2+m
NSEv[i] <- nse(GagedTmp[,c],ModeledTmp[,c])
NSELOGv[i] <- nselog(GagedTmp[,c],ModeledTmp[,c])
RMSEv[i] <- rmse(GagedTmp[,c],ModeledTmp[,c])
PBIASv[i] <- pbias(GagedTmp[,c],ModeledTmp[,c])
PEARSONv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="pearson")
SPEARMANv[i] <- cor(GagedTmp[,c],ModeledTmp[,c],method="spearman")
source('C:/Users/jlthomps/Desktop/git/USGS-NWC/R/standalone_scripts/stats_compare_new.r', echo=TRUE)
model_url="http://cida.usgs.gov/nwc/thredds/sos/watersmart/afinch/afinch-SE-SPARSE1-0.1.nc?request=GetObservation&service=SOS&version=1.0.0&offering"
#model_url="http://cida.usgs.gov/gdp/proxy/http://cida-wiwsc-gdp1qa.er.usgs.gov:8080/thredds/sos/watersmart/waters/waters-Special-0.3.nc?request=GetObservation&service=SOS&version=1.0.0&offering"
sos_url_temp="http://waterservices.usgs.gov/nwis/dv/?format=rdb,1.0&sites="
offering_temp='00003'
property_temp='00060'
drainage_url="http://waterservices.usgs.gov/nwis/site/?siteOutput=Expanded&site="
scenario_url=paste(substr(model_url,1,regexpr("Get",model_url)-1),"GetCapabilities&service=SOS&version=1.0.0",sep="")
setwd('/Users/jlthomps/Documents/R/')
system("rm graph*png")
system("rm monthly*txt")
#a<-read.csv(header=F,colClasses=c("character"),text=sites)
#a2<-read.csv(header=F,colClasses=c("character"),text=modsites)
#a<-read.csv("sites_waters_stat.txt",header=F,colClasses=c("character"))
#a2<-read.csv("sites_waters_stat.txt",header=F,colClasses=c("character"))
getcap<-getScenarioSites(scenario_url)
modprop<-getcap$modprop
a<-t(getcap$scenario_sites)
a2<-a
al<-length(a)
comment<-vector(length=al)
ObsFlowStats <- matrix(nrow=al,ncol=138)
ModFlowStats <- matrix(nrow=nrow(ObsFlowStats),ncol=ncol(ObsFlowStats))
GoFMetrics <- matrix(nrow=nrow(ObsFlowStats),ncol=108)
MonAnnGoF <- matrix(nrow=nrow(ObsFlowStats),ncol=84)
yv<-vector(length=al)
ymaxv<-vector(length=al)
modsites<-"02208450"
sites<-modsites
url<-paste(model_url,'=',modsites,'&observedProperty=',modprop,sep='',collapse=NULL)
x_mod<-SWE_CSV_IHA(url)
startdate<-min(x_mod$date)
enddate<-max(x_mod$date)
interval<-''
latest<-''
url2<-paste(sos_url_temp,sites,'&startDT=',startdate,'&endDT=',enddate,'&statCd=',offering_temp,'&parameterCd=',property_temp,'&access=3',sep='')
x_obs <- retrieveNWISData(url2)
obs_data <- get_obsdata(x_obs)
x_mod$date <- as.Date(x_mod$date,format="%Y-%m-%d")
x_mod<-x_mod[x_mod$date>=min(x_obs$date) & x_mod$date<=max(x_obs$date), ]
drain_url<-paste(drainage_url,sites,sep="")
drain_area<-getDrainageArea(drain_url)
mod_data <- get_obsdata(x_mod)
countbyyr<-aggregate(obs_data$discharge, list(obs_data$wy_val), length)
countbyyr_mod<-aggregate(mod_data$discharge, list(mod_data$wy_val), length)
colnames(countbyyr)<-c('wy','num_samples')
colnames(countbyyr_mod)<-c('wy','num_samples')
sub_countbyyr<-subset(countbyyr,num_samples >= 365)
sub_countbyyr_mod<-subset(countbyyr_mod,num_samples >= 365)
include_yrs<-merge(sub_countbyyr,sub_countbyyr_mod)
obs_data<-merge(obs_data,include_yrs,by.x="wy_val",by.y="wy")
mod_data<-merge(mod_data,include_yrs,by.x="wy_val",by.y="wy")
yv[i]<-as.character(min(obs_data$date))
ymaxv[i]<-as.character(max(obs_data$date))
x_modz<-mod_data$discharge
x_obsz<-obs_data$discharge
dates<-as.Date(obs_data$date)
file<-paste("graph",toString(sites),".png",sep="")
#png(file)
ggof(x_modz,x_obsz,na.rm=FALSE,dates,main=modsites)
dev.copy(png,file)
dev.off()
file<-paste("monthly_mean_ts_obs",toString(sites),".txt",sep="")
monthly_mean<-monthly.mean.ts(obs_data)
write.table(monthly_mean,file=file,col.names=TRUE, row.names=FALSE, quote=FALSE, sep="\t")
file<-paste("monthly_mean_ts_mod",toString(sites),".txt",sep="")
monthly_mean<-monthly.mean.ts(mod_data)
write.table(monthly_mean,file=file,col.names=TRUE, row.names=FALSE, quote=FALSE, sep="\t")
obs_data <- obs_data[,c('wy_val','date','discharge','month_val','year_val','day_val','jul_val')]
mod_data <- mod_data[,c('wy_val','date','discharge','month_val','year_val','day_val','jul_val')]
ObsFlowStats[i,] <- FlowStats(obs_data,drain_area)
ModFlowStats[i,] <- FlowStats(mod_data,drain_area)
comment <- ""
GoFMetrics[i,] <- SiteGoF(obs_data,mod_data)
MonAnnGoF[i,] <- MonthlyAnnualGoF(obs_data,mod_data)
str(obs_data)
str(mod_data)
SiteGoF(obs_data,mod_data)
MonthlyAnnualGoF(obs_data,mod_data)
source('C:/Users/jlthomps/Desktop/git/USGS-NWC/R/standalone_scripts/stats_compare_new.r', echo=TRUE)
warnings()
url <- "http://waterservices.usgs.gov/nwis/dv/?format=waterml,1.1&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(url)
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
content
View(content)
url <- "http://waterservices.usgs.gov/nwis/dv/?format=waterml,1.1&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(url)
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
url <- "http://waterservices.usgs.gov/nwis/dv/?format=waterml,1.1&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(url)
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
url <- "http://waterservices.usgs.gov/nwis/dv/?format=waterml,1.1&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(url)
View(content)
csv_url <- "http://waterservices.usgs.gov/nwis/dv/?format=rdb&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(csv_url)
length(content)
content <- readLines(csv_url)
length(content)
View(content)
content <- readLines(csv_url)
length(content)
View(content)
View(content)
url <- "http://waterservices.usgs.gov/nwis/dv/?format=waterml,1.1&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(url)
View(content)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
View(content)
csv_url <- "http://waterservices.usgs.gov/nwis/dv/?format=rdb&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
content <- readLines(csv_url)
content <- readLines(csv_url)
View(content)
?readLines
library(Rcurl)
library(RCurl)
url <- "http://waterservices.usgs.gov/nwis/dv/?format=waterml,1.1&sites=02213000&startDT=1900-01-01&endDT=2012-10-01&statCd=00003&parameterCd=00060&access=3"
getURLContent(url)
content <- getURLContent(url)
length(content)
nrow(content)
nchar(content)
content <- getURLContent(url)
nchar(content)
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
library(XML)
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
View(doc)
doc
length(doc)
?xmlTreeParse
?tryCatch
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
content
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
content <- readLines(url)
content
tail content
content tail
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
content <- readLines(url)
length(content)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
doc
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator(class="XMLParserErrorList", immediate=TRUE))
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator(class="XMLParserErrorList", immediate=TRUE))
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator(class="XMLParserErrorList", immediate=FALSE))
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)}))
doc
content <- getURLContent(url)
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)}))
doc
content <- readLines(url)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
content <- readLines(url)
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator(),XMLErrorCumulator = function(e) {cat("incomplete",e$message)})
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator())
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator()))
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator())
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator())))
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),XMLError = function(e) {cat("incomplete",e$message)})
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=NULL),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)})
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)})
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator())
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc
content2 <- getURLContent(url)
content2 <- getURLContent(url)
doc <- capture.output(tryCatch(xmlTreeParse(content2, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc
doc <- xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator())
doc<-xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE)
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE, error=xmlErrorCumulator()))
doc <- tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)})
doc
doc <- tryCatch(xmlTreeParse(content2, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)})
doc
doc <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc
doc2 <- capture.output(tryCatch(xmlTreeParse(content2, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc2
length(doc)
length(doc2)
str(doc)
str(doc2)
values<-xpathSApply(doc, "//ns1:timeSeries//ns1:value")
test <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc <- xmlTreeParse(content, getDTD=F, internalNodes=TRUE)
str(content)
doc <- xmlTreeParse(content, getDTD=F, internalNodes=TRUE)
doc <- xmlTreeParse(content, getDTD=F)
content <- getURLContent(url)
test <- capture.output(tryCatch(xmlTreeParse(content, getDTD=F, useInternalNodes=TRUE),"XMLParserErrorList" = function(e) {cat("incomplete",e$message)}))
doc <- xmlTreeParse(content, getDTD=F, internalNodes=TRUE)
length(content)
nchar(content)
test
doc <- xmlTreeParse(content, getDTD=F, internalNodes=TRUE, error=NULL)
doc <- xmlTreeParse(content, getDTD=F, error=NULL)
doc
values<-xpathSApply(doc, "//ns1:timeSeries//ns1:value")
str(doc)
str(content)
nrow(content)
ncol(content)
type(content)
typeof(content)
content2 <- readLines(url)
typeof(content2)
content2
content
xmlTreeParse(content)
xmlTreeParse(content2)
doc<-xmlTreeParse(content)
doc2<-xmlTreeParse(content2)
doc
doc2
typeof(doc)
typeof(doc2)
length(doc)
length(doc2)
values<-xpathSApply(doc, "//ns1:timeSeries//ns1:value")
values<-xpathSApply(doc2, "//ns1:timeSeries//ns1:value")
library(XML)
library(zoo)
library(chron)
library(doBy)
library(RCurl)
values<-xpathSApply(doc2, "//ns1:timeSeries//ns1:value")
values<-xpathSApply(doc, "//ns1:timeSeries//ns1:value")
doc2<-xmlTreeParse(content2,getDTD=F,internalNodes=TRUE)
htmlTreeParse(content,asText=TRUE)
test<-htmlTreeParse(content,asText=TRUE)
doc<-xmlTreeParse(test,getDTD=F,internalNodes=TRUE)
doc<-xmlTreeParse(test)
test<-htmlTreeParse(content,useInternalNodes=TRUE)
xpathSApply(text,"//ns1:timeSeries//ns1:value")
typeof(test)
test
test<-htmlTreeParse(content,useInternalNodes=TRUE,asText=T)
xpathSApply(text,"//ns1:timeSeries//ns1:value")
typeof(test)
xpathSApply(test,"//ns1:timeSeries//ns1:value")
test<-htmlTreeParse(content,useInternalNodes=TRUE)
xpathSApply(test,"//ns1:timeSeries//ns1:value")
View(test)
rstudio::viewData(dfcvbyyrf)
fix(test)
library(XML)
library(zoo)
library(chron)
library(doBy)
library(hydroGOF)
library(RCurl)
library(devtools)
library(devtools)
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/")
load_all("HITHATStats/",reset = TRUE)
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/HITHATStats")
document()
check()
run_examples()
# test()   Assumes testthat type tests in GLRI/inst/tests
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/")
build("HITHATStats")
install("HITHATStats")
library(devtools)
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/")
load_all("NWCCompare/",reset = TRUE)
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/NWCCompare")
document()
check()
run_examples()
# test()   Assumes testthat type tests in GLRI/inst/tests
setwd("C:/Users/jlthomps/Desktop/git/USGS-NWC/R/RProjects/")
build("NWCCompare")
install("NWCCompare")
